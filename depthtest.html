<html>
    <head>
<style>
body {
    margin: 0;
  }
  #c {
    width: 100vw;
    height: 100vh;
    display: block;
  }
  #capture{
				position: absolute;
				left: 20px;
				top: 20px;
				padding: 10px;
				border: 1px solid white;
				z-index: 100;
				cursor: pointer;
				background-color: rgba( 0,0,0,.4);
			}
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/seedrandom/3.0.5/seedrandom.min.js"></script>
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://fake-vs-real-stereo.glitch.me/ocean.js"></script>
    <script src="js/CubemapToEquirectangular.js"></script>
    <script src="js/CubeOrthographicCamera.js"></script>
    <script src="js/WebGLDepthRenderer.js"></script>
</head>
<body>
  <canvas id="c"></canvas>
  <div id="capture" >Capture</div>

  <script>
    function main() {

      const canvas = document.querySelector('#c');
      const renderer = new THREE.WebGLRenderer({canvas});
      const depthRenderer = new THREE.WebGLDepthRenderer({canvas});

      // Not used, but needed for the camera to be created. This is not used 
      // because depth textures on cube render targets are not supported. Instead,
      // we use the standard render target
      const notUsedCubeRenderTarget = new THREE.WebGLCubeRenderTarget(128);

      // Use a cube camera so that we don't need to manually initialize the 6 
      // perspective cameras needed for a cubemap.
      const invisibleFov = 90;
      const invisibleAspect = 1;
      const invisibleNear = 0.1;
      const invisibleFar = 100;
      const invisibleCubeCamera = new THREE.CubeCamera(invisibleNear, invisibleFar, notUsedCubeRenderTarget)

      // Choose the camera we'll by default render to the canvas.
      let canvasCameraIndex = 5;

      // Setup the scene that we'll use to render the depth values to a texture.
      const scenePackage = setupScene(invisibleCubeCamera);
      const invisibleScene = scenePackage.scene;
      const cameraPole = scenePackage.cameraPole;
    
      // depth render target will hold depth values from original scene in color 
      // channel. wont need the depth or stencil buffers for this color-only render
      // target
      const cubeRenderTarget = new THREE.WebGLCubeRenderTarget(1024, {
        depthBuffer: false,
        stenciBuffer: false,
      });

      // Use orthographic cameras since we'll be rendering to flat "TV screen"
      // planes.
      const cubeCamera = new THREE.CubeOrthographicCamera(-1, 1, 1, -1, -1, 1, cubeRenderTarget);
    
      // Animate the scene: rotate the camera around, render the depth at each
      // frame.
      function render(time) {
        time *= 0.001;
    
        if (resizeRendererToDisplaySize(depthRenderer)) {
          const canvas = depthRenderer.domElement;
          // TODO: update DepthRenderer 
          // invisibleRenderTarget.setSize(canvas.width, canvas.height);
          depthRenderer.invisibleRenderTarget.setSize(canvas.width, canvas.height);

          // TODO: this causes the depth texture to be blank - all black?
          // cubeRenderTarget.setSize(canvas.width, canvas.height);
          setCubeCameraAspect(invisibleCubeCamera, canvas.clientWidth / canvas.clientHeight);
        }
    
        cameraPole.rotation.y = time * .1;

        depthRenderer.setRenderTarget(null);
        depthRenderer.render(invisibleScene, invisibleCubeCamera.children[5]);
    
        requestAnimationFrame(render);
      }
      requestAnimationFrame(render); // begin animation

      // Setup cubemap to equirectangular conversion
      const equi = new CubemapToEquirectangular( renderer, false );

      /**
       * User Interaction
       */

      document.getElementById( 'capture' ).addEventListener( 'click', function( e ) {
          // Reset aspect ratio to 1. No idea why this is needed, but it is.
          setCubeCameraAspect(invisibleCubeCamera, 1);

          // Render the depth texture to all faces of the cube, one at a time
          for (let i = 0; i < 6; i++) {
            renderDepthTo(cubeRenderTarget, i);
          }

          // Unmanaged conversion. Do not use managed version since it will attempt 
          // a re-render. We previously manually rendered every cube face ourselves
          // already. This manual rendering, face by face, to save the depth values,
          // is necessary, since the *cube render target doesnt support depth textures.
          equi.convert( cubeCamera );
      });

      document.addEventListener('keydown', function(e) {
        if (e.keyCode >= 49 && e.keyCode < 55) {
          canvasCameraIndex = e.keyCode - 49;
        }
      });

      /**
       * Utilities
       */

      function setCubeCameraAspect(cubeCamera, aspect) {
        for (let camera of cubeCamera.children) {
          camera.aspect = aspect;
          camera.updateProjectionMatrix();
        }
      }

      function resizeRendererToDisplaySize(renderer) {
        const canvas = renderer.domElement;
        const width = canvas.clientWidth;
        const height = canvas.clientHeight;
        const needResize = canvas.width !== width || canvas.height !== height;
        if (needResize) {
          renderer.setSize(width, height, false);
        }
        return needResize;
      }

      function getCameras(cameraIndex) {
        // Select appropriate cameras given camera index
        let depthCamera = cubeCamera.children[cameraIndex]; // camera in depth space
        let invisibleCamera = invisibleCubeCamera.children[cameraIndex]; // camera in invisible space

        return {depthCamera, invisibleCamera};
      }

      function renderDepthTo(renderTarget, cameraIndex = 6) {
        let {depthCamera, invisibleCamera} = getCameras(cameraIndex);

        // draw render target scene to render target
        renderer.setRenderTarget(depthRenderer.invisibleRenderTarget);
        renderer.render(invisibleScene, invisibleCamera);
        renderer.setRenderTarget(null);

        // set active cube face if the render target is a cube render target
        var activeCubeFace = renderTarget instanceof THREE.WebGLCubeRenderTarget ? cameraIndex : undefined;
        
        // render the depth texture to the provided target
        renderer.setRenderTarget(renderTarget, activeCubeFace);
        renderer.render(depthRenderer.depthScene, depthRenderer.depthCamera);
        renderer.setRenderTarget(null);
      }
    }

    function setupScene(camera) {
        const scene = new THREE.Scene();
        scene.background = new THREE.Color('white');
      
        // put the camera on a pole (parent it to an object)
        // so we can spin the pole to move the camera around the scene
        const cameraPole = new THREE.Object3D();
        scene.add(cameraPole);
        cameraPole.add(camera);
      
        {
          const color = 0xFFFFFF;
          const intensity = 1;
          const light = new THREE.DirectionalLight(color, intensity);
          light.position.set(-1, 2, 4);
          scene.add(light);
        }
    
        const boxWidth = 1;
        const boxHeight = 1;
        const boxDepth = 1;
        const geometry = new THREE.BoxGeometry(boxWidth, boxHeight, boxDepth);
      
        function rand(min, max) {
          if (max === undefined) {
            max = min;
            min = 0;
          }
          return min + (max - min) * Math.random();
        }
      
        function randomColor() {
          return `hsl(${rand(360) | 0}, ${rand(50, 100) | 0}%, 50%)`;
        }
      
        const numObjects = 100;
        for (let i = 0; i < numObjects; ++i) {
          const material = new THREE.MeshPhongMaterial({
            color: randomColor(),
          });
      
          const cube = new THREE.Mesh(geometry, material);
          scene.add(cube);
      
          cube.position.set(rand(-20, 20), rand(-20, 20), rand(-20, 20));
          cube.rotation.set(rand(Math.PI), rand(Math.PI), 0);
          cube.scale.set(rand(3, 6), rand(3, 6), rand(3, 6));
        }

        return {scene, cameraPole};
      }
    
    main();
    </script>
</body>

</html>